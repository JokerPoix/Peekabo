{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52b98b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/c-enjalbert/.cache/kagglehub/datasets/kedarsai/bird-species-classification-220-categories/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"kedarsai/bird-species-classification-220-categories\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75fcee73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-16 20:08:50.313626: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750097330.331374   45853 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750097330.336672   45853 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1750097330.349887   45853 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750097330.349912   45853 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750097330.349913   45853 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750097330.349915   45853 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-16 20:08:50.354183: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(\"chriamue/bird-species-classifier\")\n",
    "model = AutoModelForImageClassification.from_pretrained(\"chriamue/bird-species-classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "758db279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNetForImageClassification(\n",
       "  (efficientnet): EfficientNetModel(\n",
       "    (embeddings): EfficientNetEmbeddings(\n",
       "      (padding): ZeroPad2d((0, 1, 0, 1))\n",
       "      (convolution): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=valid, bias=False)\n",
       "      (batchnorm): BatchNorm2d(32, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (activation): SiLU()\n",
       "    )\n",
       "    (encoder): EfficientNetEncoder(\n",
       "      (blocks): ModuleList(\n",
       "        (0): EfficientNetBlock(\n",
       "          (depthwise_conv): EfficientNetDepthwiseLayer(\n",
       "            (depthwise_conv_pad): ZeroPad2d((0, 1, 0, 1))\n",
       "            (depthwise_conv): EfficientNetDepthwiseConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=32, bias=False)\n",
       "            (depthwise_norm): BatchNorm2d(32, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (depthwise_act): SiLU()\n",
       "          )\n",
       "          (squeeze_excite): EfficientNetSqueezeExciteLayer(\n",
       "            (squeeze): AdaptiveAvgPool2d(output_size=1)\n",
       "            (reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (act_reduce): SiLU()\n",
       "            (act_expand): Sigmoid()\n",
       "          )\n",
       "          (projection): EfficientNetFinalBlockLayer(\n",
       "            (project_conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (project_bn): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): EfficientNetBlock(\n",
       "          (depthwise_conv): EfficientNetDepthwiseLayer(\n",
       "            (depthwise_conv_pad): ZeroPad2d((0, 1, 0, 1))\n",
       "            (depthwise_conv): EfficientNetDepthwiseConv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=16, bias=False)\n",
       "            (depthwise_norm): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (depthwise_act): SiLU()\n",
       "          )\n",
       "          (squeeze_excite): EfficientNetSqueezeExciteLayer(\n",
       "            (squeeze): AdaptiveAvgPool2d(output_size=1)\n",
       "            (reduce): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (expand): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (act_reduce): SiLU()\n",
       "            (act_expand): Sigmoid()\n",
       "          )\n",
       "          (projection): EfficientNetFinalBlockLayer(\n",
       "            (project_conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (project_bn): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (dropout): Dropout(p=0.008695652173913044, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): EfficientNetBlock(\n",
       "          (expansion): EfficientNetExpansionLayer(\n",
       "            (expand_conv): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (expand_bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (expand_act): SiLU()\n",
       "          )\n",
       "          (depthwise_conv): EfficientNetDepthwiseLayer(\n",
       "            (depthwise_conv_pad): ZeroPad2d((0, 1, 0, 1))\n",
       "            (depthwise_conv): EfficientNetDepthwiseConv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=valid, groups=96, bias=False)\n",
       "            (depthwise_norm): BatchNorm2d(96, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (depthwise_act): SiLU()\n",
       "          )\n",
       "          (squeeze_excite): EfficientNetSqueezeExciteLayer(\n",
       "            (squeeze): AdaptiveAvgPool2d(output_size=1)\n",
       "            (reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (act_reduce): SiLU()\n",
       "            (act_expand): Sigmoid()\n",
       "          )\n",
       "          (projection): EfficientNetFinalBlockLayer(\n",
       "            (project_conv): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (project_bn): BatchNorm2d(24, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (dropout): Dropout(p=0.017391304347826087, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): EfficientNetBlock(\n",
       "          (expansion): EfficientNetExpansionLayer(\n",
       "            (expand_conv): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (expand_bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (expand_act): SiLU()\n",
       "          )\n",
       "          (depthwise_conv): EfficientNetDepthwiseLayer(\n",
       "            (depthwise_conv_pad): ZeroPad2d((0, 1, 0, 1))\n",
       "            (depthwise_conv): EfficientNetDepthwiseConv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=144, bias=False)\n",
       "            (depthwise_norm): BatchNorm2d(144, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (depthwise_act): SiLU()\n",
       "          )\n",
       "          (squeeze_excite): EfficientNetSqueezeExciteLayer(\n",
       "            (squeeze): AdaptiveAvgPool2d(output_size=1)\n",
       "            (reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (act_reduce): SiLU()\n",
       "            (act_expand): Sigmoid()\n",
       "          )\n",
       "          (projection): EfficientNetFinalBlockLayer(\n",
       "            (project_conv): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (project_bn): BatchNorm2d(24, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (dropout): Dropout(p=0.026086956521739136, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): EfficientNetBlock(\n",
       "          (expansion): EfficientNetExpansionLayer(\n",
       "            (expand_conv): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (expand_bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (expand_act): SiLU()\n",
       "          )\n",
       "          (depthwise_conv): EfficientNetDepthwiseLayer(\n",
       "            (depthwise_conv_pad): ZeroPad2d((0, 1, 0, 1))\n",
       "            (depthwise_conv): EfficientNetDepthwiseConv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=144, bias=False)\n",
       "            (depthwise_norm): BatchNorm2d(144, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (depthwise_act): SiLU()\n",
       "          )\n",
       "          (squeeze_excite): EfficientNetSqueezeExciteLayer(\n",
       "            (squeeze): AdaptiveAvgPool2d(output_size=1)\n",
       "            (reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (act_reduce): SiLU()\n",
       "            (act_expand): Sigmoid()\n",
       "          )\n",
       "          (projection): EfficientNetFinalBlockLayer(\n",
       "            (project_conv): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (project_bn): BatchNorm2d(24, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (dropout): Dropout(p=0.034782608695652174, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): EfficientNetBlock(\n",
       "          (expansion): EfficientNetExpansionLayer(\n",
       "            (expand_conv): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (expand_bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (expand_act): SiLU()\n",
       "          )\n",
       "          (depthwise_conv): EfficientNetDepthwiseLayer(\n",
       "            (depthwise_conv_pad): ZeroPad2d((2, 2, 2, 2))\n",
       "            (depthwise_conv): EfficientNetDepthwiseConv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=valid, groups=144, bias=False)\n",
       "            (depthwise_norm): BatchNorm2d(144, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (depthwise_act): SiLU()\n",
       "          )\n",
       "          (squeeze_excite): EfficientNetSqueezeExciteLayer(\n",
       "            (squeeze): AdaptiveAvgPool2d(output_size=1)\n",
       "            (reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (act_reduce): SiLU()\n",
       "            (act_expand): Sigmoid()\n",
       "          )\n",
       "          (projection): EfficientNetFinalBlockLayer(\n",
       "            (project_conv): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (project_bn): BatchNorm2d(48, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (dropout): Dropout(p=0.043478260869565216, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): EfficientNetBlock(\n",
       "          (expansion): EfficientNetExpansionLayer(\n",
       "            (expand_conv): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (expand_bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (expand_act): SiLU()\n",
       "          )\n",
       "          (depthwise_conv): EfficientNetDepthwiseLayer(\n",
       "            (depthwise_conv_pad): ZeroPad2d((1, 2, 1, 2))\n",
       "            (depthwise_conv): EfficientNetDepthwiseConv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=same, groups=288, bias=False)\n",
       "            (depthwise_norm): BatchNorm2d(288, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (depthwise_act): SiLU()\n",
       "          )\n",
       "          (squeeze_excite): EfficientNetSqueezeExciteLayer(\n",
       "            (squeeze): AdaptiveAvgPool2d(output_size=1)\n",
       "            (reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (act_reduce): SiLU()\n",
       "            (act_expand): Sigmoid()\n",
       "          )\n",
       "          (projection): EfficientNetFinalBlockLayer(\n",
       "            (project_conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (project_bn): BatchNorm2d(48, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (dropout): Dropout(p=0.05217391304347827, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): EfficientNetBlock(\n",
       "          (expansion): EfficientNetExpansionLayer(\n",
       "            (expand_conv): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (expand_bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (expand_act): SiLU()\n",
       "          )\n",
       "          (depthwise_conv): EfficientNetDepthwiseLayer(\n",
       "            (depthwise_conv_pad): ZeroPad2d((1, 2, 1, 2))\n",
       "            (depthwise_conv): EfficientNetDepthwiseConv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=same, groups=288, bias=False)\n",
       "            (depthwise_norm): BatchNorm2d(288, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (depthwise_act): SiLU()\n",
       "          )\n",
       "          (squeeze_excite): EfficientNetSqueezeExciteLayer(\n",
       "            (squeeze): AdaptiveAvgPool2d(output_size=1)\n",
       "            (reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (act_reduce): SiLU()\n",
       "            (act_expand): Sigmoid()\n",
       "          )\n",
       "          (projection): EfficientNetFinalBlockLayer(\n",
       "            (project_conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (project_bn): BatchNorm2d(48, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (dropout): Dropout(p=0.06086956521739131, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): EfficientNetBlock(\n",
       "          (expansion): EfficientNetExpansionLayer(\n",
       "            (expand_conv): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (expand_bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (expand_act): SiLU()\n",
       "          )\n",
       "          (depthwise_conv): EfficientNetDepthwiseLayer(\n",
       "            (depthwise_conv_pad): ZeroPad2d((1, 1, 1, 1))\n",
       "            (depthwise_conv): EfficientNetDepthwiseConv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=valid, groups=288, bias=False)\n",
       "            (depthwise_norm): BatchNorm2d(288, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (depthwise_act): SiLU()\n",
       "          )\n",
       "          (squeeze_excite): EfficientNetSqueezeExciteLayer(\n",
       "            (squeeze): AdaptiveAvgPool2d(output_size=1)\n",
       "            (reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (act_reduce): SiLU()\n",
       "            (act_expand): Sigmoid()\n",
       "          )\n",
       "          (projection): EfficientNetFinalBlockLayer(\n",
       "            (project_conv): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (project_bn): BatchNorm2d(88, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (dropout): Dropout(p=0.06956521739130435, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): EfficientNetBlock(\n",
       "          (expansion): EfficientNetExpansionLayer(\n",
       "            (expand_conv): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (expand_bn): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (expand_act): SiLU()\n",
       "          )\n",
       "          (depthwise_conv): EfficientNetDepthwiseLayer(\n",
       "            (depthwise_conv_pad): ZeroPad2d((0, 1, 0, 1))\n",
       "            (depthwise_conv): EfficientNetDepthwiseConv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=528, bias=False)\n",
       "            (depthwise_norm): BatchNorm2d(528, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (depthwise_act): SiLU()\n",
       "          )\n",
       "          (squeeze_excite): EfficientNetSqueezeExciteLayer(\n",
       "            (squeeze): AdaptiveAvgPool2d(output_size=1)\n",
       "            (reduce): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (expand): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (act_reduce): SiLU()\n",
       "            (act_expand): Sigmoid()\n",
       "          )\n",
       "          (projection): EfficientNetFinalBlockLayer(\n",
       "            (project_conv): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (project_bn): BatchNorm2d(88, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (dropout): Dropout(p=0.0782608695652174, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): EfficientNetBlock(\n",
       "          (expansion): EfficientNetExpansionLayer(\n",
       "            (expand_conv): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (expand_bn): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (expand_act): SiLU()\n",
       "          )\n",
       "          (depthwise_conv): EfficientNetDepthwiseLayer(\n",
       "            (depthwise_conv_pad): ZeroPad2d((0, 1, 0, 1))\n",
       "            (depthwise_conv): EfficientNetDepthwiseConv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=528, bias=False)\n",
       "            (depthwise_norm): BatchNorm2d(528, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (depthwise_act): SiLU()\n",
       "          )\n",
       "          (squeeze_excite): EfficientNetSqueezeExciteLayer(\n",
       "            (squeeze): AdaptiveAvgPool2d(output_size=1)\n",
       "            (reduce): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (expand): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (act_reduce): SiLU()\n",
       "            (act_expand): Sigmoid()\n",
       "          )\n",
       "          (projection): EfficientNetFinalBlockLayer(\n",
       "            (project_conv): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (project_bn): BatchNorm2d(88, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (dropout): Dropout(p=0.08695652173913043, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): EfficientNetBlock(\n",
       "          (expansion): EfficientNetExpansionLayer(\n",
       "            (expand_conv): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (expand_bn): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (expand_act): SiLU()\n",
       "          )\n",
       "          (depthwise_conv): EfficientNetDepthwiseLayer(\n",
       "            (depthwise_conv_pad): ZeroPad2d((0, 1, 0, 1))\n",
       "            (depthwise_conv): EfficientNetDepthwiseConv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=528, bias=False)\n",
       "            (depthwise_norm): BatchNorm2d(528, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (depthwise_act): SiLU()\n",
       "          )\n",
       "          (squeeze_excite): EfficientNetSqueezeExciteLayer(\n",
       "            (squeeze): AdaptiveAvgPool2d(output_size=1)\n",
       "            (reduce): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (expand): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (act_reduce): SiLU()\n",
       "            (act_expand): Sigmoid()\n",
       "          )\n",
       "          (projection): EfficientNetFinalBlockLayer(\n",
       "            (project_conv): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (project_bn): BatchNorm2d(88, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (dropout): Dropout(p=0.09565217391304348, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): EfficientNetBlock(\n",
       "          (expansion): EfficientNetExpansionLayer(\n",
       "            (expand_conv): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (expand_bn): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (expand_act): SiLU()\n",
       "          )\n",
       "          (depthwise_conv): EfficientNetDepthwiseLayer(\n",
       "            (depthwise_conv_pad): ZeroPad2d((1, 2, 1, 2))\n",
       "            (depthwise_conv): EfficientNetDepthwiseConv2d(528, 528, kernel_size=(5, 5), stride=(1, 1), padding=same, groups=528, bias=False)\n",
       "            (depthwise_norm): BatchNorm2d(528, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (depthwise_act): SiLU()\n",
       "          )\n",
       "          (squeeze_excite): EfficientNetSqueezeExciteLayer(\n",
       "            (squeeze): AdaptiveAvgPool2d(output_size=1)\n",
       "            (reduce): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (expand): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (act_reduce): SiLU()\n",
       "            (act_expand): Sigmoid()\n",
       "          )\n",
       "          (projection): EfficientNetFinalBlockLayer(\n",
       "            (project_conv): Conv2d(528, 120, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (project_bn): BatchNorm2d(120, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (dropout): Dropout(p=0.10434782608695654, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): EfficientNetBlock(\n",
       "          (expansion): EfficientNetExpansionLayer(\n",
       "            (expand_conv): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (expand_bn): BatchNorm2d(720, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (expand_act): SiLU()\n",
       "          )\n",
       "          (depthwise_conv): EfficientNetDepthwiseLayer(\n",
       "            (depthwise_conv_pad): ZeroPad2d((1, 2, 1, 2))\n",
       "            (depthwise_conv): EfficientNetDepthwiseConv2d(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=same, groups=720, bias=False)\n",
       "            (depthwise_norm): BatchNorm2d(720, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (depthwise_act): SiLU()\n",
       "          )\n",
       "          (squeeze_excite): EfficientNetSqueezeExciteLayer(\n",
       "            (squeeze): AdaptiveAvgPool2d(output_size=1)\n",
       "            (reduce): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (expand): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (act_reduce): SiLU()\n",
       "            (act_expand): Sigmoid()\n",
       "          )\n",
       "          (projection): EfficientNetFinalBlockLayer(\n",
       "            (project_conv): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (project_bn): BatchNorm2d(120, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (dropout): Dropout(p=0.11304347826086956, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): EfficientNetBlock(\n",
       "          (expansion): EfficientNetExpansionLayer(\n",
       "            (expand_conv): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (expand_bn): BatchNorm2d(720, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (expand_act): SiLU()\n",
       "          )\n",
       "          (depthwise_conv): EfficientNetDepthwiseLayer(\n",
       "            (depthwise_conv_pad): ZeroPad2d((1, 2, 1, 2))\n",
       "            (depthwise_conv): EfficientNetDepthwiseConv2d(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=same, groups=720, bias=False)\n",
       "            (depthwise_norm): BatchNorm2d(720, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (depthwise_act): SiLU()\n",
       "          )\n",
       "          (squeeze_excite): EfficientNetSqueezeExciteLayer(\n",
       "            (squeeze): AdaptiveAvgPool2d(output_size=1)\n",
       "            (reduce): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (expand): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (act_reduce): SiLU()\n",
       "            (act_expand): Sigmoid()\n",
       "          )\n",
       "          (projection): EfficientNetFinalBlockLayer(\n",
       "            (project_conv): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (project_bn): BatchNorm2d(120, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (dropout): Dropout(p=0.12173913043478261, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): EfficientNetBlock(\n",
       "          (expansion): EfficientNetExpansionLayer(\n",
       "            (expand_conv): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (expand_bn): BatchNorm2d(720, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (expand_act): SiLU()\n",
       "          )\n",
       "          (depthwise_conv): EfficientNetDepthwiseLayer(\n",
       "            (depthwise_conv_pad): ZeroPad2d((1, 2, 1, 2))\n",
       "            (depthwise_conv): EfficientNetDepthwiseConv2d(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=same, groups=720, bias=False)\n",
       "            (depthwise_norm): BatchNorm2d(720, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (depthwise_act): SiLU()\n",
       "          )\n",
       "          (squeeze_excite): EfficientNetSqueezeExciteLayer(\n",
       "            (squeeze): AdaptiveAvgPool2d(output_size=1)\n",
       "            (reduce): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (expand): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (act_reduce): SiLU()\n",
       "            (act_expand): Sigmoid()\n",
       "          )\n",
       "          (projection): EfficientNetFinalBlockLayer(\n",
       "            (project_conv): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (project_bn): BatchNorm2d(120, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (dropout): Dropout(p=0.13043478260869565, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): EfficientNetBlock(\n",
       "          (expansion): EfficientNetExpansionLayer(\n",
       "            (expand_conv): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (expand_bn): BatchNorm2d(720, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (expand_act): SiLU()\n",
       "          )\n",
       "          (depthwise_conv): EfficientNetDepthwiseLayer(\n",
       "            (depthwise_conv_pad): ZeroPad2d((2, 2, 2, 2))\n",
       "            (depthwise_conv): EfficientNetDepthwiseConv2d(720, 720, kernel_size=(5, 5), stride=(2, 2), padding=valid, groups=720, bias=False)\n",
       "            (depthwise_norm): BatchNorm2d(720, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (depthwise_act): SiLU()\n",
       "          )\n",
       "          (squeeze_excite): EfficientNetSqueezeExciteLayer(\n",
       "            (squeeze): AdaptiveAvgPool2d(output_size=1)\n",
       "            (reduce): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (expand): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (act_reduce): SiLU()\n",
       "            (act_expand): Sigmoid()\n",
       "          )\n",
       "          (projection): EfficientNetFinalBlockLayer(\n",
       "            (project_conv): Conv2d(720, 208, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (project_bn): BatchNorm2d(208, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (dropout): Dropout(p=0.1391304347826087, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): EfficientNetBlock(\n",
       "          (expansion): EfficientNetExpansionLayer(\n",
       "            (expand_conv): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (expand_bn): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (expand_act): SiLU()\n",
       "          )\n",
       "          (depthwise_conv): EfficientNetDepthwiseLayer(\n",
       "            (depthwise_conv_pad): ZeroPad2d((1, 2, 1, 2))\n",
       "            (depthwise_conv): EfficientNetDepthwiseConv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=same, groups=1248, bias=False)\n",
       "            (depthwise_norm): BatchNorm2d(1248, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (depthwise_act): SiLU()\n",
       "          )\n",
       "          (squeeze_excite): EfficientNetSqueezeExciteLayer(\n",
       "            (squeeze): AdaptiveAvgPool2d(output_size=1)\n",
       "            (reduce): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (expand): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (act_reduce): SiLU()\n",
       "            (act_expand): Sigmoid()\n",
       "          )\n",
       "          (projection): EfficientNetFinalBlockLayer(\n",
       "            (project_conv): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (project_bn): BatchNorm2d(208, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (dropout): Dropout(p=0.14782608695652175, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): EfficientNetBlock(\n",
       "          (expansion): EfficientNetExpansionLayer(\n",
       "            (expand_conv): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (expand_bn): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (expand_act): SiLU()\n",
       "          )\n",
       "          (depthwise_conv): EfficientNetDepthwiseLayer(\n",
       "            (depthwise_conv_pad): ZeroPad2d((1, 2, 1, 2))\n",
       "            (depthwise_conv): EfficientNetDepthwiseConv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=same, groups=1248, bias=False)\n",
       "            (depthwise_norm): BatchNorm2d(1248, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (depthwise_act): SiLU()\n",
       "          )\n",
       "          (squeeze_excite): EfficientNetSqueezeExciteLayer(\n",
       "            (squeeze): AdaptiveAvgPool2d(output_size=1)\n",
       "            (reduce): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (expand): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (act_reduce): SiLU()\n",
       "            (act_expand): Sigmoid()\n",
       "          )\n",
       "          (projection): EfficientNetFinalBlockLayer(\n",
       "            (project_conv): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (project_bn): BatchNorm2d(208, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (dropout): Dropout(p=0.1565217391304348, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): EfficientNetBlock(\n",
       "          (expansion): EfficientNetExpansionLayer(\n",
       "            (expand_conv): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (expand_bn): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (expand_act): SiLU()\n",
       "          )\n",
       "          (depthwise_conv): EfficientNetDepthwiseLayer(\n",
       "            (depthwise_conv_pad): ZeroPad2d((1, 2, 1, 2))\n",
       "            (depthwise_conv): EfficientNetDepthwiseConv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=same, groups=1248, bias=False)\n",
       "            (depthwise_norm): BatchNorm2d(1248, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (depthwise_act): SiLU()\n",
       "          )\n",
       "          (squeeze_excite): EfficientNetSqueezeExciteLayer(\n",
       "            (squeeze): AdaptiveAvgPool2d(output_size=1)\n",
       "            (reduce): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (expand): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (act_reduce): SiLU()\n",
       "            (act_expand): Sigmoid()\n",
       "          )\n",
       "          (projection): EfficientNetFinalBlockLayer(\n",
       "            (project_conv): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (project_bn): BatchNorm2d(208, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (dropout): Dropout(p=0.16521739130434784, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): EfficientNetBlock(\n",
       "          (expansion): EfficientNetExpansionLayer(\n",
       "            (expand_conv): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (expand_bn): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (expand_act): SiLU()\n",
       "          )\n",
       "          (depthwise_conv): EfficientNetDepthwiseLayer(\n",
       "            (depthwise_conv_pad): ZeroPad2d((1, 2, 1, 2))\n",
       "            (depthwise_conv): EfficientNetDepthwiseConv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=same, groups=1248, bias=False)\n",
       "            (depthwise_norm): BatchNorm2d(1248, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (depthwise_act): SiLU()\n",
       "          )\n",
       "          (squeeze_excite): EfficientNetSqueezeExciteLayer(\n",
       "            (squeeze): AdaptiveAvgPool2d(output_size=1)\n",
       "            (reduce): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (expand): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (act_reduce): SiLU()\n",
       "            (act_expand): Sigmoid()\n",
       "          )\n",
       "          (projection): EfficientNetFinalBlockLayer(\n",
       "            (project_conv): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (project_bn): BatchNorm2d(208, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (dropout): Dropout(p=0.17391304347826086, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): EfficientNetBlock(\n",
       "          (expansion): EfficientNetExpansionLayer(\n",
       "            (expand_conv): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (expand_bn): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (expand_act): SiLU()\n",
       "          )\n",
       "          (depthwise_conv): EfficientNetDepthwiseLayer(\n",
       "            (depthwise_conv_pad): ZeroPad2d((0, 1, 0, 1))\n",
       "            (depthwise_conv): EfficientNetDepthwiseConv2d(1248, 1248, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=1248, bias=False)\n",
       "            (depthwise_norm): BatchNorm2d(1248, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (depthwise_act): SiLU()\n",
       "          )\n",
       "          (squeeze_excite): EfficientNetSqueezeExciteLayer(\n",
       "            (squeeze): AdaptiveAvgPool2d(output_size=1)\n",
       "            (reduce): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (expand): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (act_reduce): SiLU()\n",
       "            (act_expand): Sigmoid()\n",
       "          )\n",
       "          (projection): EfficientNetFinalBlockLayer(\n",
       "            (project_conv): Conv2d(1248, 352, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (project_bn): BatchNorm2d(352, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (dropout): Dropout(p=0.1826086956521739, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): EfficientNetBlock(\n",
       "          (expansion): EfficientNetExpansionLayer(\n",
       "            (expand_conv): Conv2d(352, 2112, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (expand_bn): BatchNorm2d(2112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (expand_act): SiLU()\n",
       "          )\n",
       "          (depthwise_conv): EfficientNetDepthwiseLayer(\n",
       "            (depthwise_conv_pad): ZeroPad2d((0, 1, 0, 1))\n",
       "            (depthwise_conv): EfficientNetDepthwiseConv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=2112, bias=False)\n",
       "            (depthwise_norm): BatchNorm2d(2112, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (depthwise_act): SiLU()\n",
       "          )\n",
       "          (squeeze_excite): EfficientNetSqueezeExciteLayer(\n",
       "            (squeeze): AdaptiveAvgPool2d(output_size=1)\n",
       "            (reduce): Conv2d(2112, 88, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (expand): Conv2d(88, 2112, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "            (act_reduce): SiLU()\n",
       "            (act_expand): Sigmoid()\n",
       "          )\n",
       "          (projection): EfficientNetFinalBlockLayer(\n",
       "            (project_conv): Conv2d(2112, 352, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "            (project_bn): BatchNorm2d(352, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "            (dropout): Dropout(p=0.19130434782608696, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (top_conv): Conv2d(352, 1408, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "      (top_bn): BatchNorm2d(1408, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (top_activation): SiLU()\n",
       "    )\n",
       "    (pooler): AvgPool2d(kernel_size=1408, stride=1408, padding=0)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (classifier): Linear(in_features=1408, out_features=525, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9498c021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bird Species Classification Script\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import random\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_model():\n",
    "    \"\"\"Load pre-trained bird species classifier from Hugging Face\"\"\"\n",
    "    print(\"Loading bird species classifier model...\")\n",
    "    processor = AutoImageProcessor.from_pretrained(\"chriamue/bird-species-classifier\")\n",
    "    model = AutoModelForImageClassification.from_pretrained(\"chriamue/bird-species-classifier\")\n",
    "    model.eval()\n",
    "    return processor, model\n",
    "\n",
    "def predict_bird_species(image_path, processor, model):\n",
    "    \"\"\"\n",
    "    Predict bird species from an image file\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the bird image\n",
    "        processor: Image processor for the model\n",
    "        model: Loaded bird classification model\n",
    "    \n",
    "    Returns:\n",
    "        str: Predicted bird species\n",
    "        float: Confidence score\n",
    "    \"\"\"\n",
    "    # Load and preprocess image\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    # Prepare image for the model\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    \n",
    "    # Get prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Get probabilities\n",
    "    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    \n",
    "    # Get predicted class\n",
    "    predicted_class_idx = probs.argmax().item()\n",
    "    predicted_label = model.config.id2label[predicted_class_idx]\n",
    "    confidence = probs[0][predicted_class_idx].item()\n",
    "    \n",
    "    return predicted_label, confidence\n",
    "\n",
    "def display_prediction(image_path, species, confidence):\n",
    "    \"\"\"Display image with prediction and confidence\"\"\"\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Predicted Species: {species}\\nConfidence: {confidence:.2%}\", fontsize=14)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def test_random_images(dataset_path, processor, model, num_images=5):\n",
    "    \"\"\"Test model on random images from dataset\"\"\"\n",
    "    # Find image directories\n",
    "    image_dirs = []\n",
    "    for root, dirs, files in os.walk(dataset_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                image_dirs.append(root)\n",
    "                break\n",
    "    \n",
    "    image_dirs = list(set(image_dirs))  # Remove duplicates\n",
    "    \n",
    "    if not image_dirs:\n",
    "        print(f\"No image directories found in {dataset_path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(image_dirs)} species directories\")\n",
    "    \n",
    "    # Select random species directories\n",
    "    selected_dirs = random.sample(image_dirs, min(num_images, len(image_dirs)))\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for directory in selected_dirs:\n",
    "        # Get species name from directory\n",
    "        species_name = os.path.basename(directory)\n",
    "        \n",
    "        # Get all images in directory\n",
    "        image_files = [f for f in os.listdir(directory) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        \n",
    "        if not image_files:\n",
    "            continue\n",
    "        \n",
    "        # Select random image\n",
    "        image_file = random.choice(image_files)\n",
    "        image_path = os.path.join(directory, image_file)\n",
    "        \n",
    "        # Predict\n",
    "        predicted_species, confidence = predict_bird_species(image_path, processor, model)\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            'image_path': image_path,\n",
    "            'true_species': species_name,\n",
    "            'predicted_species': predicted_species,\n",
    "            'confidence': confidence\n",
    "        })\n",
    "        \n",
    "        # Display\n",
    "        print(f\"\\nTrue species: {species_name}\")\n",
    "        display_prediction(image_path, predicted_species, confidence)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    correct = sum(1 for r in results if r['predicted_species'].lower() == r['true_species'].lower())\n",
    "    accuracy = correct / len(results) if results else 0\n",
    "    print(f\"\\nAccuracy on random sample: {accuracy:.2%} ({correct}/{len(results)})\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "440ef8d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (4051413643.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    return\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "# Define path to the dataset\n",
    "dataset_path = \"/home/c-enjalbert/Documents/EPSI/Architecture_IA(M.Mandon)/kedarsai_bird-species-classification-220-categories\"\n",
    "\n",
    "# Check if the path exists\n",
    "if not os.path.exists(dataset_path):\n",
    "    print(f\"Dataset path {dataset_path} does not exist.\")\n",
    "    print(\"Please update the path to where you downloaded the dataset using kagglehub.\")\n",
    "    return\n",
    "\n",
    "# Load model\n",
    "processor, model = load_model()\n",
    "\n",
    "# Option 1: Test on a specific image\n",
    "# sample_image = \"path/to/your/bird/image.jpg\"\n",
    "# species, confidence = predict_bird_species(sample_image, processor, model)\n",
    "# display_prediction(sample_image, species, confidence)\n",
    "\n",
    "# Option 2: Test on random images from dataset\n",
    "print(\"Testing on random images from dataset...\")\n",
    "test_random_images(dataset_path, processor, model, num_images=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e17839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bird Species Batch Classification Script\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def load_model():\n",
    "    \"\"\"Load pre-trained bird species classifier from Hugging Face\"\"\"\n",
    "    print(\"Loading bird species classifier model...\")\n",
    "    processor = AutoImageProcessor.from_pretrained(\"chriamue/bird-species-classifier\")\n",
    "    model = AutoModelForImageClassification.from_pretrained(\"chriamue/bird-species-classifier\")\n",
    "    model.eval()\n",
    "    return processor, model\n",
    "\n",
    "def predict_single_image(args):\n",
    "    \"\"\"Helper function for parallel processing\"\"\"\n",
    "    image_path, processor, model = args\n",
    "    try:\n",
    "        # Load and preprocess image\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        \n",
    "        # Prepare image for the model\n",
    "        inputs = processor(images=image, return_tensors=\"pt\")\n",
    "        \n",
    "        # Get prediction\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        # Get probabilities\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        \n",
    "        # Get top 3 predictions\n",
    "        top_indices = torch.topk(probs, k=3).indices[0].tolist()\n",
    "        top_probs = torch.topk(probs, k=3).values[0].tolist()\n",
    "        \n",
    "        # Get predicted labels\n",
    "        predicted_labels = [model.config.id2label[idx] for idx in top_indices]\n",
    "        \n",
    "        return {\n",
    "            'image_path': image_path,\n",
    "            'top_predictions': predicted_labels,\n",
    "            'confidences': top_probs\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'image_path': image_path,\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "def batch_predict(image_paths, processor, model, max_workers=4):\n",
    "    \"\"\"\n",
    "    Process multiple images in batch using parallel processing\n",
    "    \n",
    "    Args:\n",
    "        image_paths (list): List of paths to bird images\n",
    "        processor: Image processor for the model\n",
    "        model: Loaded bird classification model\n",
    "        max_workers (int): Maximum number of parallel workers\n",
    "    \n",
    "    Returns:\n",
    "        list: Prediction results for each image\n",
    "    \"\"\"\n",
    "    print(f\"Processing {len(image_paths)} images with {max_workers} workers...\")\n",
    "    results = []\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        args_list = [(path, processor, model) for path in image_paths]\n",
    "        for result in tqdm(executor.map(predict_single_image, args_list), total=len(args_list)):\n",
    "            results.append(result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def find_all_images(base_dir):\n",
    "    \"\"\"Find all image files in directory and subdirectories\"\"\"\n",
    "    image_paths = []\n",
    "    for root, _, files in os.walk(base_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                image_paths.append(os.path.join(root, file))\n",
    "    return image_paths\n",
    "\n",
    "def visualize_batch_results(results, num_samples=5):\n",
    "    \"\"\"Visualize a sample of batch prediction results\"\"\"\n",
    "    if not results:\n",
    "        print(\"No results to visualize\")\n",
    "        return\n",
    "    \n",
    "    # Filter out errors\n",
    "    valid_results = [r for r in results if 'error' not in r]\n",
    "    if not valid_results:\n",
    "        print(\"All results contain errors\")\n",
    "        return\n",
    "    \n",
    "    # Sample results to visualize\n",
    "    sample_results = random.sample(valid_results, min(num_samples, len(valid_results)))\n",
    "    \n",
    "    # Create a grid of images\n",
    "    fig, axes = plt.subplots(1, len(sample_results), figsize=(4*len(sample_results), 4))\n",
    "    if len(sample_results) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, result in enumerate(sample_results):\n",
    "        # Load image\n",
    "        img = Image.open(result['image_path'])\n",
    "        \n",
    "        # Display image\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"Top prediction:\\n{result['top_predictions'][0]}\\n{result['confidences'][0]:.1%}\")\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def save_results_to_csv(results, output_path):\n",
    "    \"\"\"Save batch prediction results to CSV file\"\"\"\n",
    "    # Convert results to DataFrame\n",
    "    data = []\n",
    "    for result in results:\n",
    "        if 'error' in result:\n",
    "            data.append({\n",
    "                'image_path': result['image_path'],\n",
    "                'top_prediction': 'ERROR',\n",
    "                'confidence': 0.0,\n",
    "                'error': result['error']\n",
    "            })\n",
    "        else:\n",
    "            data.append({\n",
    "                'image_path': result['image_path'],\n",
    "                'top_prediction': result['top_predictions'][0],\n",
    "                'confidence': result['confidences'][0],\n",
    "                'second_prediction': result['top_predictions'][1] if len(result['top_predictions']) > 1 else '',\n",
    "                'second_confidence': result['confidences'][1] if len(result['confidences']) > 1 else 0.0,\n",
    "                'third_prediction': result['top_predictions'][2] if len(result['top_predictions']) > 2 else '',\n",
    "                'third_confidence': result['confidences'][2] if len(result['confidences']) > 2 else 0.0\n",
    "            })\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Results saved to {output_path}\")\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40677ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path /home/c-enjalbert/Documents/EPSI/Architecture_IA(M.Mandon)/kedarsai_bird-species-classification-220-categories does not exist.\n",
      "Please update the path to where you downloaded the dataset using kagglehub.\n",
      "Loading bird species classifier model...\n",
      "Found 0 images in the dataset.\n",
      "Processing 0 images with 4 workers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No results to visualize\n",
      "Results saved to bird_classification_results.csv\n",
      "\n",
      "Classification Results Summary:\n",
      "Total images processed: 0\n",
      "Images with errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Define path to the dataset\n",
    "dataset_path = \"/home/c-enjalbert/Documents/EPSI/Architecture_IA(M.Mandon)/kedarsai_bird-species-classification-220-categories\"\n",
    "\n",
    "# Check if the path exists\n",
    "if not os.path.exists(dataset_path):\n",
    "    print(f\"Dataset path {dataset_path} does not exist.\")\n",
    "    print(\"Please update the path to where you downloaded the dataset using kagglehub.\")\n",
    "# Load model\n",
    "processor, model = load_model()\n",
    "\n",
    "# Find all images or a subset\n",
    "all_image_paths = find_all_images(dataset_path)\n",
    "print(f\"Found {len(all_image_paths)} images in the dataset.\")\n",
    "\n",
    "# Use a smaller sample for testing (optional)\n",
    "sample_size = 100  # Adjust as needed\n",
    "image_paths = random.sample(all_image_paths, min(sample_size, len(all_image_paths)))\n",
    "\n",
    "# Process images in batch\n",
    "results = batch_predict(image_paths, processor, model)\n",
    "\n",
    "# Visualize some results\n",
    "visualize_batch_results(results, num_samples=5)\n",
    "\n",
    "# Save results to CSV\n",
    "output_file = \"bird_classification_results.csv\"\n",
    "df = save_results_to_csv(results, output_file)\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nClassification Results Summary:\")\n",
    "print(f\"Total images processed: {len(results)}\")\n",
    "print(f\"Images with errors: {sum(1 for r in results if 'error' in r)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
